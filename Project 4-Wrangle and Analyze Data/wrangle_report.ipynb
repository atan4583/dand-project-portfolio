{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report\n",
    "\n",
    " ---\n",
    "# <center>~ Wrangle and Analyze Data ~</center>\n",
    "# <center>Audrey S Tan </center>\n",
    "# <center>April, 2019 </center>\n",
    "\n",
    "In this project, I applied the concepts learned from the lessons in Data Wrangling, gathered data from a variety of sources and in a variety of formats, assessed its quality and tidiness, then cleaned it. From the cleansed dataset, I went on to produce 3 data insights and visualizations. Below is the summary of the Gather, Assess, Clean, Analyze and Visualization steps I went through:\n",
    "\n",
    "1) Gather data from three different sources:\n",
    "   - WeRateDogs Twitter archive. This is provided by Udacity in a csv file format and contains 5000+ basic tweet data about dog rating, name, and \"stage\". \n",
    "   - Tweet image predictions. This is also provided by Udacity in tsv file format which I downloaded programmatically from Udacity site. This file contains dog breed prediction results (from a Neural Network classifier) for every dog images from the WeRateDogs Twitter archive.\n",
    "   - Additional Twitter Data. The data resides on Twitter site and can be pulled via their API tweepy. I used the API to query additional data (in JSON format) and downloaded into a file named tweet_json.txt. This file has favorite and retweet count information for each tweet ID in the WeRateDogs Twitter archive, which are crucial for the dog rating analysis. \n",
    "\n",
    "2) Assess data for quality and tidiness:\n",
    "   - I inspected the three datasets visually and programmatically to produce a list of quality and tidiness issues. \n",
    "   - Quality issues include:     \n",
    ">    + various issues pertains to incorrect rating numerator and denominator values in the main twitter dataset.\n",
    ">    + inproper data types for tweet id, timestamp, rating numerator and denominator in the main twitter dataset. \n",
    ">    + invalid dog names and inconsistent dog naming convention in the main and secondary twitter datasets.\n",
    ">    + presence of retweet and reply-to data in the main and secondary twitter data datasets.\n",
    ">    + superfluous columns in the main twitter data dataset.\n",
    "   - Tidiness issues include:\n",
    ">    + dog stages span four different columns in the main twitter dataset which can and should be combined into one.\n",
    ">    + three types of observations (dog, non dog and partial) in the prediction dataset\n",
    ">    + the three datasets can be combined into one single dataset\n",
    "\n",
    "3) Clean data to fix quality and tidiness issues identified:\n",
    "  - for each of the issues identified in each dataset, prescribed a code fix, built, executed and tested the code fix. \n",
    "  - combined the three datasets into a single master dataset, store it to a csv file and a python database table.\n",
    "\n",
    "4) Analyze and visualize the wrangled data: \n",
    "  - looked at the cleaned master dataset and produce three insights with visualizations.\n",
    "  - Insights and visulizations produced include:\n",
    ">   + correlation between favorite and retweet counts.\n",
    ">   + the trend of favorite and retweet counts with respect to time and classification of dog species\n",
    ">   + performance of the dog image classifier\n",
    "\n",
    " ---\n",
    "<footer style=\"float:right; color:#999; background:#fff;\">\n",
    "Created by Audrey S Tan.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dand)",
   "language": "python",
   "name": "dand"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
